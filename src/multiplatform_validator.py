"""
üöÄ –ú–£–õ–¨–¢–ò–ü–õ–ê–¢–§–û–†–ú–ï–ù–ù–´–ô –í–ê–õ–ò–î–ê–¢–û–† SaaS –ò–î–ï–ô

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Reddit, Twitter/X –∏ LinkedIn –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
"""

from .reddit_scraper import RedditSaaSValidator
from .twitter_scraper import TwitterSaaSValidator, TwitterAdvancedSearch
from .linkedin_scraper import LinkedInSaaSValidator
import pandas as pd
import json
from datetime import datetime
from collections import Counter
import os


class MultiPlatformValidator:
    """
    –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º
    """
    
    def __init__(self, reddit_creds=None, twitter_creds=None, linkedin_creds=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º
        
        Args:
            reddit_creds: dict {'client_id': '', 'client_secret': '', 'user_agent': ''}
            twitter_creds: dict {'bearer_token': ''}
            linkedin_creds: dict {'email': '', 'password': ''}
        """
        self.platforms = {}
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Reddit
        if reddit_creds:
            try:
                self.platforms['reddit'] = RedditSaaSValidator(
                    client_id=reddit_creds['client_id'],
                    client_secret=reddit_creds['client_secret'],
                    user_agent=reddit_creds['user_agent']
                )
                print("‚úÖ Reddit –ø–æ–¥–∫–ª—é—á–µ–Ω")
            except Exception as e:
                print(f"‚ö†Ô∏è Reddit –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω: {e}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Twitter
        if twitter_creds:
            try:
                self.platforms['twitter'] = TwitterSaaSValidator(
                    bearer_token=twitter_creds['bearer_token']
                )
                print("‚úÖ Twitter/X –ø–æ–¥–∫–ª—é—á–µ–Ω")
            except Exception as e:
                print(f"‚ö†Ô∏è Twitter –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω: {e}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LinkedIn
        if linkedin_creds:
            try:
                self.platforms['linkedin'] = LinkedInSaaSValidator(
                    email=linkedin_creds['email'],
                    password=linkedin_creds['password']
                )
                print("‚úÖ LinkedIn –ø–æ–¥–∫–ª—é—á–µ–Ω")
            except Exception as e:
                print(f"‚ö†Ô∏è LinkedIn –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω: {e}")
    
    def validate_idea(self, idea_name, keywords, subreddits=None, 
                     target_job_titles=None, competitor_names=None,
                     output_dir='validation_results'):
        """
        –ü–æ–ª–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏–¥–µ–∏ —á–µ—Ä–µ–∑ –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
        
        Args:
            idea_name: –Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∞—à–µ–π –∏–¥–µ–∏
            keywords: —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
            subreddits: —Å–ø–∏—Å–æ–∫ subreddit'–æ–≤ –¥–ª—è Reddit
            target_job_titles: —Å–ø–∏—Å–æ–∫ —Ü–µ–ª–µ–≤—ã—Ö –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π –¥–ª—è LinkedIn
            competitor_names: —Å–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
            output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"\n{'='*70}")
        print(f"üéØ –ú–£–õ–¨–¢–ò–ü–õ–ê–¢–§–û–†–ú–ï–ù–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø: {idea_name}")
        print(f"{'='*70}\n")
        
        results = {
            'idea_name': idea_name,
            'analysis_date': datetime.now().isoformat(),
            'keywords': keywords,
            'platforms_analyzed': [],
            'reddit_data': {},
            'twitter_data': {},
            'linkedin_data': {},
            'overall_score': 0,
            'verdict': '',
            'key_insights': [],
            'recommendations': []
        }
        
        platform_scores = {}
        
        # ============ REDDIT –ê–ù–ê–õ–ò–ó ============
        if 'reddit' in self.platforms and subreddits:
            print("\nüì± REDDIT –ê–ù–ê–õ–ò–ó")
            print("-" * 70)
            
            try:
                reddit_validation = self.platforms['reddit'].validate_saas_idea(
                    idea_keywords=keywords,
                    relevant_subreddits=subreddits,
                    output_file=f'{output_dir}/reddit_validation.json'
                )
                
                results['platforms_analyzed'].append('reddit')
                results['reddit_data'] = {
                    'posts_found': reddit_validation.get('posts_found', 0),
                    'pain_points': reddit_validation.get('pain_points_found', 0),
                    'market_size': reddit_validation.get('market_size_estimate', 0),
                    'score': reddit_validation.get('validation_score', 0),
                    'verdict': reddit_validation.get('verdict', '')
                }
                
                platform_scores['reddit'] = reddit_validation.get('validation_score', 0)
                
                print(f"  ‚úÖ Reddit: {results['reddit_data']['posts_found']} –ø–æ—Å—Ç–æ–≤, "
                      f"{results['reddit_data']['pain_points']} pain points")
                print(f"  üìä –û—Ü–µ–Ω–∫–∞: {results['reddit_data']['score']}/100")
                
            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ Reddit: {e}")
        
        # ============ TWITTER –ê–ù–ê–õ–ò–ó ============
        if 'twitter' in self.platforms:
            print("\nüê¶ TWITTER/X –ê–ù–ê–õ–ò–ó")
            print("-" * 70)
            
            try:
                twitter_report, twitter_df = self.platforms['twitter'].generate_report(
                    keywords=keywords,
                    output_file=f'{output_dir}/twitter_analysis.json'
                )
                
                if twitter_report:
                    results['platforms_analyzed'].append('twitter')
                    results['twitter_data'] = {
                        'tweets_found': twitter_report.get('total_tweets', 0),
                        'pain_points': twitter_report.get('pain_points_count', 0),
                        'avg_engagement': twitter_report.get('engagement_stats', {}).get('avg_likes', 0),
                        'total_engagement': twitter_report.get('engagement_stats', {}).get('total_engagement', 0),
                        'top_hashtags': list(twitter_report.get('top_hashtags', {}).keys())[:5]
                    }
                    
                    # Scoring –¥–ª—è Twitter (0-100)
                    twitter_score = 0
                    if results['twitter_data']['tweets_found'] > 50:
                        twitter_score += 30
                    elif results['twitter_data']['tweets_found'] > 20:
                        twitter_score += 20
                    
                    if results['twitter_data']['pain_points'] > 10:
                        twitter_score += 30
                    elif results['twitter_data']['pain_points'] > 5:
                        twitter_score += 20
                    
                    if results['twitter_data']['avg_engagement'] > 50:
                        twitter_score += 20
                    elif results['twitter_data']['avg_engagement'] > 20:
                        twitter_score += 10
                    
                    if results['twitter_data']['total_engagement'] > 1000:
                        twitter_score += 20
                    elif results['twitter_data']['total_engagement'] > 500:
                        twitter_score += 10
                    
                    platform_scores['twitter'] = twitter_score
                    results['twitter_data']['score'] = twitter_score
                    
                    print(f"  ‚úÖ Twitter: {results['twitter_data']['tweets_found']} —Ç–≤–∏—Ç–æ–≤, "
                          f"{results['twitter_data']['pain_points']} pain points")
                    print(f"  üìä –û—Ü–µ–Ω–∫–∞: {twitter_score}/100")
                
            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ Twitter: {e}")
        
        # ============ LINKEDIN –ê–ù–ê–õ–ò–ó ============
        if 'linkedin' in self.platforms and target_job_titles:
            print("\nüíº LINKEDIN –ê–ù–ê–õ–ò–ó")
            print("-" * 70)
            
            try:
                linkedin_validation = self.platforms['linkedin'].validate_b2b_market(
                    target_job_titles=target_job_titles,
                    competitor_names=competitor_names or [],
                    product_keywords=keywords,
                    output_file=f'{output_dir}/linkedin_b2b_validation.json'
                )
                
                results['platforms_analyzed'].append('linkedin')
                results['linkedin_data'] = {
                    'market_size': linkedin_validation.get('market_size', 0),
                    'competitors': len(linkedin_validation.get('competitors_data', [])),
                    'score': linkedin_validation.get('validation_score', 0),
                    'verdict': linkedin_validation.get('verdict', '')
                }
                
                platform_scores['linkedin'] = linkedin_validation.get('validation_score', 0)
                
                print(f"  ‚úÖ LinkedIn: {results['linkedin_data']['market_size']} –ø—Ä–æ—Ñ–∏–ª–µ–π, "
                      f"{results['linkedin_data']['competitors']} –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤")
                print(f"  üìä –û—Ü–µ–Ω–∫–∞: {results['linkedin_data']['score']}/100")
                
            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ LinkedIn: {e}")
        
        # ============ –û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê ============
        if platform_scores:
            # –°—Ä–µ–¥–Ω–µ–≤–∑–≤–µ—à–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            results['overall_score'] = int(sum(platform_scores.values()) / len(platform_scores))
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤
            results['key_insights'] = self._generate_insights(results)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            results['recommendations'] = self._generate_recommendations(results)
            
            # –í–µ—Ä–¥–∏–∫—Ç
            score = results['overall_score']
            if score >= 80:
                results['verdict'] = "üöÄ –û–¢–õ–ò–ß–ù–ê–Ø –ò–î–ï–Ø - –°–∏–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è"
            elif score >= 60:
                results['verdict'] = "‚úÖ –•–û–†–û–®–ê–Ø –ò–î–ï–Ø - –ï—Å—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª"
            elif score >= 40:
                results['verdict'] = "‚ö†Ô∏è –°–†–ï–î–ù–Ø–Ø –ò–î–ï–Ø - –ù—É–∂–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"
            else:
                results['verdict'] = "‚ùå –°–õ–ê–ë–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è pivot"
            
            print(f"\n{'='*70}")
            print(f"üìä –û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê: {results['overall_score']}/100")
            print(f"üìã {results['verdict']}")
            print(f"{'='*70}\n")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –æ—Ç—á—ë—Ç–∞
            with open(f'{output_dir}/multiplatform_report.json', 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            
            return results
        else:
            print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∏ —Å –æ–¥–Ω–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã")
            results['verdict'] = "‚ùå –ù–ï–¢ –î–ê–ù–ù–´–•"
            return results
    
    def _generate_insights(self, results):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        insights = []
        
        # Reddit –∏–Ω—Å–∞–π—Ç—ã
        if 'reddit' in results['platforms_analyzed']:
            reddit_data = results['reddit_data']
            if reddit_data.get('pain_points', 0) > 20:
                insights.append(f"–ù–∞ Reddit –Ω–∞–π–¥–µ–Ω–æ {reddit_data['pain_points']} –±–æ–ª–µ–≤—ã—Ö —Ç–æ—á–µ–∫ - –ø—Ä–æ–±–ª–µ–º–∞ —Ä–µ–∞–ª—å–Ω–∞")
            if reddit_data.get('market_size', 0) > 100000:
                insights.append(f"–ë–æ–ª—å—à–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è –Ω–∞ Reddit ({reddit_data['market_size']:,} –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤)")
        
        # Twitter –∏–Ω—Å–∞–π—Ç—ã
        if 'twitter' in results['platforms_analyzed']:
            twitter_data = results['twitter_data']
            if twitter_data.get('total_engagement', 0) > 1000:
                insights.append(f"–í—ã—Å–æ–∫–∏–π engagement –Ω–∞ Twitter ({twitter_data['total_engagement']:,}) - —Ç–µ–º–∞ –ø–æ–ø—É–ª—è—Ä–Ω–∞")
            if twitter_data.get('top_hashtags'):
                top_hashtag = twitter_data['top_hashtags'][0]
                insights.append(f"–ü–æ–ø—É–ª—è—Ä–Ω—ã–π —Ö–µ—à—Ç–µ–≥: #{top_hashtag}")
        
        # LinkedIn –∏–Ω—Å–∞–π—Ç—ã
        if 'linkedin' in results['platforms_analyzed']:
            linkedin_data = results['linkedin_data']
            if linkedin_data.get('market_size', 0) > 500:
                insights.append(f"–ë–æ–ª—å—à–∞—è B2B –∞—É–¥–∏—Ç–æ—Ä–∏—è –Ω–∞ LinkedIn ({linkedin_data['market_size']}+ –ø—Ä–æ—Ñ–∏–ª–µ–π)")
            if linkedin_data.get('competitors', 0) > 0:
                insights.append(f"–ù–∞–π–¥–µ–Ω–æ {linkedin_data['competitors']} –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ - —Ä—ã–Ω–æ–∫ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        
        # –û–±—â–∏–µ –∏–Ω—Å–∞–π—Ç—ã
        if results['overall_score'] >= 70:
            insights.append("–ò–¥–µ—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–∏–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞—Ö")
        
        return insights[:10]  # –ú–∞–∫—Å 10 –∏–Ω—Å–∞–π—Ç–æ–≤
    
    def _generate_recommendations(self, results):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        recommendations = []
        score = results['overall_score']
        
        if score >= 80:
            recommendations.append("–ù–∞—á–Ω–∏—Ç–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É MVP –∫–∞–∫ –º–æ–∂–Ω–æ —Å–∫–æ—Ä–µ–µ")
            recommendations.append("–°–æ–∑–¥–∞–π—Ç–µ landing page –∏ —Å–æ–±–µ—Ä–∏—Ç–µ email-–ø–æ–¥–ø–∏—Å–∫–∏")
            recommendations.append("–ü—Ä–æ–≤–µ–¥–∏—Ç–µ –∏–Ω—Ç–µ—Ä–≤—å—é —Å 10-20 potential customers")
        elif score >= 60:
            recommendations.append("–£–≥–ª—É–±–∏—Ç–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö pain points")
            recommendations.append("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –¥–µ—Ç–∞–ª—å–Ω–æ")
            recommendations.append("–°–æ–∑–¥–∞–π—Ç–µ –ø—Ä–æ—Å—Ç–æ–π landing page –¥–ª—è —Å–±–æ—Ä–∞ –∏–Ω—Ç–µ—Ä–µ—Å–∞")
        elif score >= 40:
            recommendations.append("–ü—Ä–æ–≤–µ–¥–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ customer interviews")
            recommendations.append("–£—Ç–æ—á–Ω–∏—Ç–µ —Ü–µ–ª–µ–≤—É—é –∞—É–¥–∏—Ç–æ—Ä–∏—é")
            recommendations.append("–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Å—É–∂–µ–Ω–∏–µ –∏–ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ scope")
        else:
            recommendations.append("–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ pivot - –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å–ª–∞–±–∞—è")
            recommendations.append("–ò–∑—É—á–∏—Ç–µ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –≤ —ç—Ç–æ–π —Å—Ñ–µ—Ä–µ")
            recommendations.append("–ü—Ä–æ–≤–µ–¥–∏—Ç–µ –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–µ customer research")
        
        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º
        if 'reddit' in results['platforms_analyzed']:
            if results['reddit_data'].get('pain_points', 0) > 10:
                recommendations.append("–ö–æ–Ω—Ç–∞–∫—Ç–∏—Ä—É–π—Ç–µ —Å –∞–≤—Ç–æ—Ä–∞–º–∏ –ø–æ—Å—Ç–æ–≤ —Å pain points –Ω–∞ Reddit")
        
        if 'twitter' in results['platforms_analyzed']:
            if results['twitter_data'].get('top_hashtags'):
                recommendations.append(f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ö–µ—à—Ç–µ–≥–∏ –¥–ª—è –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏—è: {', '.join(f'#{h}' for h in results['twitter_data']['top_hashtags'][:3])}")
        
        if 'linkedin' in results['platforms_analyzed']:
            if results['linkedin_data'].get('market_size', 0) > 100:
                recommendations.append("–ù–∞—á–Ω–∏—Ç–µ outreach –Ω–∞ LinkedIn –∫ —Ü–µ–ª–µ–≤–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏")
        
        return recommendations[:10]  # –ú–∞–∫—Å 10 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π


def main():
    """
    –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º—É–ª—å—Ç–∏–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–æ–≥–æ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞
    """
    import os
    from dotenv import load_dotenv
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ credentials
    load_dotenv()
    
    # Reddit credentials
    reddit_creds = {
        'client_id': os.getenv('REDDIT_CLIENT_ID'),
        'client_secret': os.getenv('REDDIT_CLIENT_SECRET'),
        'user_agent': os.getenv('REDDIT_USER_AGENT')
    }
    
    # Twitter credentials
    twitter_creds = {
        'bearer_token': os.getenv('TWITTER_BEARER_TOKEN')
    }
    
    # LinkedIn credentials
    linkedin_creds = {
        'email': os.getenv('LINKEDIN_EMAIL'),
        'password': os.getenv('LINKEDIN_PASSWORD')
    }
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞
    validator = MultiPlatformValidator(
        reddit_creds=reddit_creds if reddit_creds['client_id'] else None,
        twitter_creds=twitter_creds if twitter_creds['bearer_token'] else None,
        linkedin_creds=linkedin_creds if linkedin_creds['email'] else None
    )
    
    # –ü—Ä–∏–º–µ—Ä: –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–¥–µ–∏ "email marketing automation"
    print("\n" + "="*70)
    print("–ü–†–ò–ú–ï–†: –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–¥–µ–∏ 'Email Marketing Automation'")
    print("="*70)
    
    results = validator.validate_idea(
        idea_name="Email Marketing Automation",
        keywords=[
            'email marketing',
            'email automation',
            'cold email',
            'email campaign',
            'newsletter tool'
        ],
        subreddits=['marketing', 'SaaS', 'Entrepreneur', 'sales'],
        target_job_titles=['Marketing Manager', 'CMO', 'Growth Manager'],
        competitor_names=['Mailchimp', 'SendGrid', 'ConvertKit']
    )
    
    print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω!")
    print(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: validation_results/")


if __name__ == "__main__":
    main()
